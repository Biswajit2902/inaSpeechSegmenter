{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "277fd4c7-edee-49ec-ab32-7826c8eb5b8b",
   "metadata": {},
   "source": [
    "# API tutorial for _VBx-Based_ Voice Femininity Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24967d1f-af52-4297-954e-2790fbb44214",
   "metadata": {
    "tags": []
   },
   "source": [
    "Perform feature extraction on the chosen file using the **VBx extraction pipeline** and add a **pre-trained gender detection model** on the output descriptors.  \n",
    "Notice that a voice activity detection (from _inaSpeechSegmenter.Segmenter_) is performed to compute the voice femininity score using gender predictions only on speech segments (cudNN version must be at least **8.6** if you want to use **tensorflow-2.12**).  \n",
    "  \n",
    "Make sure the recording has only one speaker to get a more accurate femininity score.\n",
    "\n",
    "> VFS = 1 means the voice gender prediction is \"female\"  \n",
    "> VFS = 0 means the voice gender prediction is \"male\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bad980ae-b545-4ed8-966b-72c2a1bfe8f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-07 16:18:42.530831: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-07 16:18:43.260088: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-07 16:18:43.260150: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-07 16:18:43.260158: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from inaSpeechSegmenter.vbx_segmenter import VoiceFemininityScoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bce8116-89c2-46fd-83de-4a442b5d75e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Select a media to analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8331a19b-b699-4c0f-9082-c8ac63746824",
   "metadata": {
    "tags": []
   },
   "source": [
    "* duration < 680 ms  \n",
    "Voice femininity score = 0.000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c112d924-65a8-4435-87ac-ad8146f0300a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fpath = \"../media/0021.mp3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5767fa9d-b342-4916-98ed-5d6636f104bd",
   "metadata": {},
   "source": [
    "* only music : an assertion error is raised indicating that no speech segment was found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a78f269-126f-4ae5-a035-6053a264e86c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fpath = \"../media/silence2sec.wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3fc8e7-a318-4006-981e-b5042027b84a",
   "metadata": {},
   "source": [
    "* Example  \n",
    "Voice femininity score = 0.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c40b25a-fd7a-4d49-81dc-9ecc68f7cc9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fpath = \"../media/lamartine.wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b875f8-0e17-4fbb-98c8-15ed65a165c9",
   "metadata": {},
   "source": [
    "### Create instance of _VBx-based_ Voice Femininity Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fec6ec-5964-4632-8f61-2f6f178f3cc1",
   "metadata": {},
   "source": [
    "_gd_model_criteria_ refers to the gender detection model used :  \n",
    ">\"**bgc**\" (default) : Multi layer perceptron trained on all data giving best BGC (i.e. interspeech2023 paper)  \n",
    "\"**vbf**\" : Multi layer perceptron trained on French CommonVoice giving best VFP (i.e. interspeech2023 paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "518423cc-ab54-4fca-acdb-3347c9e7a391",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "v = VoiceFemininityScoring(backend='onnx', gd_model_criteria=\"bgc\")\n",
    "# v = VoiceFemininityScoring(backend='pytorch', gpu='0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4095553d-de59-4c20-a69d-dd98c5c3da14",
   "metadata": {},
   "source": [
    "#### Femininity score   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8e33670-d957-4f51-8936-1ae236c73d69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sdevauchelle/Documents/app/venv/lib/python3.8/site-packages/pyannote/algorithms/utils/viterbi.py:86: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.vstack(\n",
      "/home/sdevauchelle/Documents/app/venv/lib/python3.8/site-packages/pyannote/algorithms/utils/viterbi.py:95: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.vstack(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 - 0s - 344ms/epoch - 18ms/step\n",
      "Voice femininity score : 0.5532\n"
     ]
    }
   ],
   "source": [
    "vf_score = v(fpath)\n",
    "print(\"Voice femininity score : %.4f\" % vf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6564d761-7e01-41a4-b066-77d0200c795f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
